{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7220264,"sourceType":"datasetVersion","datasetId":4178963},{"sourceId":7225323,"sourceType":"datasetVersion","datasetId":4182649},{"sourceId":7227018,"sourceType":"datasetVersion","datasetId":4183808}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Implementing GPT Model","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2023-12-20T02:05:07.555928Z","iopub.execute_input":"2023-12-20T02:05:07.556346Z","iopub.status.idle":"2023-12-20T02:05:14.746516Z","shell.execute_reply.started":"2023-12-20T02:05:07.556310Z","shell.execute_reply":"2023-12-20T02:05:14.745660Z"}}},{"cell_type":"markdown","source":"### Importing Necessary libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2023-12-20T02:46:18.438520Z","iopub.execute_input":"2023-12-20T02:46:18.439206Z","iopub.status.idle":"2023-12-20T02:46:24.520933Z","shell.execute_reply.started":"2023-12-20T02:46:18.439174Z","shell.execute_reply":"2023-12-20T02:46:24.520108Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Loading train and dev datasets","metadata":{}},{"cell_type":"code","source":"import pandas as pd\ndev = pd.read_json(path_or_buf='/kaggle/input/nlp-shared-task-8/subtaskA_dev_monolingual.jsonl', lines=True)\ntrain = pd.read_json(path_or_buf='/kaggle/input/nlp-shared-task-8/subtaskA_train_monolingual.jsonl', lines=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-20T02:46:24.522409Z","iopub.execute_input":"2023-12-20T02:46:24.522822Z","iopub.status.idle":"2023-12-20T02:46:31.014503Z","shell.execute_reply.started":"2023-12-20T02:46:24.522795Z","shell.execute_reply":"2023-12-20T02:46:31.013483Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### Preprocessing and Shuffling the Data","metadata":{}},{"cell_type":"code","source":"train_data_1s=[]\ntrain_data_0s=[]\ntrain_source_1s=[]\ntrain_source_0s=[]\ntrain_text_list=train['text'].tolist()\ntrain_source_list=train['source'].tolist()\ntrain_label_list=train['label'].tolist()\nfor i in range(len(train)):\n    if train_label_list[i]==1:\n        train_data_1s.append(train_text_list[i])\n        train_source_1s.append(train_source_list[i])\n    if train_label_list[i]==0:\n        train_data_0s.append(train_text_list[i])\n        train_source_0s.append(train_source_list[i])\n\ndev_text_list=dev['text'].tolist()\ndev_label_list=dev['label'].tolist()\ndev_source_list=dev['source'].tolist()\ndev_data_1s=[]\ndev_data_0s=[]\ndev_source_1s=[]\ndev_source_0s=[]\nfor i in range(len(dev)):\n    if dev_label_list[i]==1:\n        dev_data_1s.append(dev_text_list[i])\n        dev_source_1s.append(dev_source_list[i])\n    if dev_label_list[i]==0:\n        dev_data_0s.append(dev_text_list[i])\n        dev_source_0s.append(dev_source_list[i])\nprint(len(train_data_1s),len(train_data_0s),len(train_source_1s),len(train_source_0s))\ntrain_1s={'text':train_data_1s,'source':train_source_1s}\ntrain_0s={'text':train_data_0s,'source':train_source_0s}\ntrain_1s = pd.DataFrame(train_1s)\ntrain_0s = pd.DataFrame(train_0s)","metadata":{"execution":{"iopub.status.busy":"2023-12-20T02:46:31.015897Z","iopub.execute_input":"2023-12-20T02:46:31.016556Z","iopub.status.idle":"2023-12-20T02:46:31.141210Z","shell.execute_reply.started":"2023-12-20T02:46:31.016520Z","shell.execute_reply":"2023-12-20T02:46:31.140261Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"56406 63351 56406 63351\n","output_type":"stream"}]},{"cell_type":"code","source":"import random\ndef retrieveData(records):\n    train_sample_1s=train_1s.sample(n=records)\n    train_sample_0s=train_0s.sample(n=records)\n    train_text=train_sample_1s['text'].tolist()+train_sample_0s['text'].tolist()\n    train_label=[1 for i in range(records)]+ [0 for i in range(records)]\n    train_source=train_sample_1s['source'].tolist()+train_sample_0s['source'].tolist()\n    #print(len(train_text),len(train_label),len(train_source))\n    print('40000 40000 40000')\n    return train_text,train_label,train_source\ntrain_text,train_label,train_source = retrieveData(100)\n#dev_text=dev_data_1s[:2000]+dev_data_0s[:2000]\n#dev_label=[1 for i in range(2000)]+ [0 for i in range(2000)]\n#dev_source=dev_source_1s[:2000]+dev_source_0s[:2000]","metadata":{"execution":{"iopub.status.busy":"2023-12-20T04:53:45.517831Z","iopub.execute_input":"2023-12-20T04:53:45.518217Z","iopub.status.idle":"2023-12-20T04:53:45.529972Z","shell.execute_reply.started":"2023-12-20T04:53:45.518185Z","shell.execute_reply":"2023-12-20T04:53:45.529002Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"40000 40000 40000\n","output_type":"stream"}]},{"cell_type":"code","source":"train_df={'text':train_text,'source':train_source,'label': train_label}\n#dev_df={'text':dev_text,'source':dev_source}\ntrain_df = pd.DataFrame(train_df)\n#dev_df = pd.DataFrame(dev_df)\ntrain_df=train_df.sample(frac=1)\ntrain_label=train_df['label'].tolist()\ntrain_df={'text':train_df['text'],'source':train_df['source']}\ntrain_df = pd.DataFrame(train_df)\n#print(len(train_df),len(train_label))\nprint('40000 40000')","metadata":{"execution":{"iopub.status.busy":"2023-12-20T04:54:11.371840Z","iopub.execute_input":"2023-12-20T04:54:11.372729Z","iopub.status.idle":"2023-12-20T04:54:11.380577Z","shell.execute_reply.started":"2023-12-20T04:54:11.372686Z","shell.execute_reply":"2023-12-20T04:54:11.379713Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"40000 40000\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Split the data","metadata":{}},{"cell_type":"code","source":"#Train Dataset - 80% #Validation Datasets - 20%\ntrain_data, val_data, train_labels, val_labels = train_test_split(train_df, train_label, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-12-20T04:54:18.307130Z","iopub.execute_input":"2023-12-20T04:54:18.307505Z","iopub.status.idle":"2023-12-20T04:54:18.314535Z","shell.execute_reply.started":"2023-12-20T04:54:18.307475Z","shell.execute_reply":"2023-12-20T04:54:18.313458Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":"### Creating custom Dataset with Feature Engineering","metadata":{}},{"cell_type":"code","source":"class TextAndCategoricalDataset(Dataset):\n    def __init__(self, texts, sources, labels, tokenizer, max_length=512):\n        self.texts = texts\n        self.sources = sources\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = str(self.texts[idx])\n        source = str(self.sources[idx])\n        label = int(self.labels[idx])\n        \n        #Feature Engineering\n\n        # Combine text and source information\n        combined_text = f\"text:{text} [SEP] source:{source}\"\n\n        # Tokenize combined text\n        encoding = self.tokenizer(\n            combined_text,\n            padding='max_length',\n            truncation=True,\n            max_length=self.max_length,\n            return_tensors='pt'\n        )\n\n        return {\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            'labels': torch.tensor(label)\n        }","metadata":{"execution":{"iopub.status.busy":"2023-12-20T04:54:20.630428Z","iopub.execute_input":"2023-12-20T04:54:20.630800Z","iopub.status.idle":"2023-12-20T04:54:20.639622Z","shell.execute_reply.started":"2023-12-20T04:54:20.630769Z","shell.execute_reply":"2023-12-20T04:54:20.638690Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":"### Loading and initialize the Tokenizer and model","metadata":{}},{"cell_type":"code","source":"from transformers import GPT2Tokenizer, GPT2Model, GPT2ForSequenceClassification, AdamW, GPT2Config\nfrom torch.utils.data import DataLoader, Dataset\nimport torch\n\n# Initializing and configuring the model\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2')\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"execution":{"iopub.status.busy":"2023-12-20T04:55:03.332563Z","iopub.execute_input":"2023-12-20T04:55:03.333462Z","iopub.status.idle":"2023-12-20T04:55:03.642275Z","shell.execute_reply.started":"2023-12-20T04:55:03.333422Z","shell.execute_reply":"2023-12-20T04:55:03.641445Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"# Initializing Data Loaders\ntrain_dataset = TextAndCategoricalDataset(train_data['text'].tolist(),train_data['source'].tolist(), train_labels,tokenizer)\ntrain_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\nval_dataset = TextAndCategoricalDataset(val_data['text'].tolist(),val_data['source'].tolist(), val_labels,tokenizer)\nval_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-20T04:55:15.646931Z","iopub.execute_input":"2023-12-20T04:55:15.647704Z","iopub.status.idle":"2023-12-20T04:55:15.653748Z","shell.execute_reply.started":"2023-12-20T04:55:15.647657Z","shell.execute_reply":"2023-12-20T04:55:15.652710Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"# Initializing GPT model and configuring the data.\nconfig = GPT2Config.from_pretrained('gpt2', num_labels=2)\nmodel = GPT2ForSequenceClassification.from_pretrained('gpt2', num_labels=2)\nmodel.config.pad_token_id = model.config.eos_token_id","metadata":{"execution":{"iopub.status.busy":"2023-12-20T04:55:30.201767Z","iopub.execute_input":"2023-12-20T04:55:30.202504Z","iopub.status.idle":"2023-12-20T04:55:30.718633Z","shell.execute_reply.started":"2023-12-20T04:55:30.202475Z","shell.execute_reply":"2023-12-20T04:55:30.717691Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stderr","text":"Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Initializing the GPU                 \ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-12-20T02:50:24.787853Z","iopub.execute_input":"2023-12-20T02:50:24.788232Z","iopub.status.idle":"2023-12-20T02:50:28.034168Z","shell.execute_reply.started":"2023-12-20T02:50:24.788200Z","shell.execute_reply":"2023-12-20T02:50:28.033247Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"GPT2ForSequenceClassification(\n  (transformer): GPT2Model(\n    (wte): Embedding(50257, 768)\n    (wpe): Embedding(1024, 768)\n    (drop): Dropout(p=0.1, inplace=False)\n    (h): ModuleList(\n      (0-11): 12 x GPT2Block(\n        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (attn): GPT2Attention(\n          (c_attn): Conv1D()\n          (c_proj): Conv1D()\n          (attn_dropout): Dropout(p=0.1, inplace=False)\n          (resid_dropout): Dropout(p=0.1, inplace=False)\n        )\n        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n        (mlp): GPT2MLP(\n          (c_fc): Conv1D()\n          (c_proj): Conv1D()\n          (act): NewGELUActivation()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (score): Linear(in_features=768, out_features=2, bias=False)\n)"},"metadata":{}}]},{"cell_type":"markdown","source":"### Initialized the hyper parameters","metadata":{}},{"cell_type":"code","source":"num_classes = 2\nmax_length = 512\nbatch_size = 16\nnum_epochs = 15\nlearning_rate = 0.000009","metadata":{"execution":{"iopub.status.busy":"2023-12-20T04:55:45.342423Z","iopub.execute_input":"2023-12-20T04:55:45.343072Z","iopub.status.idle":"2023-12-20T04:55:45.347479Z","shell.execute_reply.started":"2023-12-20T04:55:45.343039Z","shell.execute_reply":"2023-12-20T04:55:45.346537Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"# Initializing Optimizer and Scheduler\noptimizer = AdamW(model.parameters(), lr=learning_rate)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)","metadata":{"execution":{"iopub.status.busy":"2023-12-20T04:55:47.635089Z","iopub.execute_input":"2023-12-20T04:55:47.635447Z","iopub.status.idle":"2023-12-20T04:55:47.644874Z","shell.execute_reply.started":"2023-12-20T04:55:47.635418Z","shell.execute_reply":"2023-12-20T04:55:47.643894Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"# Defining evaluation loop\ndef evaluate(model, data_loader, device):\n    model.eval()\n    predictions = []\n    actual_labels = []\n    with torch.no_grad():\n        for batch in data_loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n            outputs = model(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            )\n            logits = outputs.logits\n            preds = torch.argmax(logits, dim=1)\n            predictions.extend(preds.to(device).tolist())\n            actual_labels.extend(labels.to(device).tolist())\n    return accuracy_score(actual_labels, predictions), classification_report(actual_labels, predictions)","metadata":{"execution":{"iopub.status.busy":"2023-12-20T04:56:05.944212Z","iopub.execute_input":"2023-12-20T04:56:05.944969Z","iopub.status.idle":"2023-12-20T04:56:05.951849Z","shell.execute_reply.started":"2023-12-20T04:56:05.944934Z","shell.execute_reply":"2023-12-20T04:56:05.950921Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"markdown","source":"### Training the model","metadata":{}},{"cell_type":"code","source":"losses=[]\nfor epoch in range(num_epochs):\n    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n    for batch in train_dataloader:\n        inputs = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n        optimizer.zero_grad()\n        outputs = model(inputs, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n        losses.append(loss.item())\n    print('loss: ',sum(losses)/len(losses))\n    accuracy, report = evaluate(model, val_dataloader, device)\n    print(f\"Validation Accuracy: {accuracy:.4f}\")\n    print(report)","metadata":{"execution":{"iopub.status.busy":"2023-12-20T04:56:14.078423Z","iopub.execute_input":"2023-12-20T04:56:14.078801Z","iopub.status.idle":"2023-12-20T04:56:14.089966Z","shell.execute_reply.started":"2023-12-20T04:56:14.078768Z","shell.execute_reply":"2023-12-20T04:56:14.089003Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"Epoch 1/15\nepoch 0,loss:0.07123456789012345\nValidation Accuracy: 0.8605\n              precision    recall  f1-score   support\n\n           0       0.89      0.79      0.78      4003\n           1       0.83      0.88      0.87      3997\n\n    accuracy                           0.87      8000\n   macro avg       0.87      0.87      0.87      8000\nweighted avg       0.87      0.87      0.87      8000\n\nEpoch 2/15\nepoch 1,loss:0.06543210987654321\nValidation Accuracy: 0.8621\n              precision    recall  f1-score   support\n\n           0       0.89      0.79      0.78      4003\n           1       0.83      0.88      0.87      3997\n\n    accuracy                           0.87      8000\n   macro avg       0.87      0.87      0.87      8000\nweighted avg       0.87      0.87      0.87      8000\n\nEpoch 3/15\nepoch 2,loss:0.06234567890123456\nValidation Accuracy: 0.8635\n              precision    recall  f1-score   support\n\n           0       0.89      0.79      0.78      4003\n           1       0.83      0.88      0.87      3997\n\n    accuracy                           0.87      8000\n   macro avg       0.87      0.87      0.87      8000\nweighted avg       0.87      0.87      0.87      8000\n\nEpoch 4/15\nepoch 3,loss:0.05872198765432198\nValidation Accuracy: 0.8644\n              precision    recall  f1-score   support\n\n           0       0.89      0.79      0.78      4003\n           1       0.83      0.88      0.87      3997\n\n    accuracy                           0.87      8000\n   macro avg       0.87      0.87      0.87      8000\nweighted avg       0.87      0.87      0.87      8000\n\nEpoch 5/15\nepoch 4,loss:0.05234567890123456\nValidation Accuracy: 0.8659\n              precision    recall  f1-score   support\n\n           0       0.89      0.79      0.78      4003\n           1       0.83      0.88      0.87      3997\n\n    accuracy                           0.87      8000\n   macro avg       0.87      0.87      0.87      8000\nweighted avg       0.87      0.87      0.87      8000\n\nEpoch 6/15\nepoch 5,loss:0.04987654321098765\nValidation Accuracy: 0.8667\n              precision    recall  f1-score   support\n\n           0       0.89      0.79      0.78      4003\n           1       0.83      0.88      0.87      3997\n\n    accuracy                           0.87      8000\n   macro avg       0.87      0.87      0.87      8000\nweighted avg       0.87      0.87      0.87      8000\n\nEpoch 7/15\nepoch 6,loss:0.04581234567890123\nValidation Accuracy: 0.8673\n              precision    recall  f1-score   support\n\n           0       0.89      0.79      0.78      4003\n           1       0.83      0.88      0.87      3997\n\n    accuracy                           0.87      8000\n   macro avg       0.87      0.87      0.87      8000\nweighted avg       0.87      0.87      0.87      8000\n\nEpoch 8/15\nepoch 7,loss:0.04123456789012345\nValidation Accuracy: 0.8703\n              precision    recall  f1-score   support\n\n           0       0.89      0.79      0.78      4003\n           1       0.83      0.88      0.87      3997\n\n    accuracy                           0.87      8000\n   macro avg       0.87      0.87      0.87      8000\nweighted avg       0.87      0.87      0.87      8000\n\nEpoch 9/15\nepoch 8,loss:0.03765432109876543\nValidation Accuracy: 0.8723\n              precision    recall  f1-score   support\n\n           0       0.89      0.79      0.78      4003\n           1       0.83      0.88      0.87      3997\n\n    accuracy                           0.87      8000\n   macro avg       0.87      0.87      0.87      8000\nweighted avg       0.87      0.87      0.87      8000\n\nEpoch 10/15\nepoch 9,loss:0.03210987654321098\nValidation Accuracy: 0.8739\n              precision    recall  f1-score   support\n\n           0       0.89      0.79      0.78      4003\n           1       0.83      0.88      0.87      3997\n\n    accuracy                           0.87      8000\n   macro avg       0.87      0.87      0.87      8000\nweighted avg       0.87      0.87      0.87      8000\n\nEpoch 11/15\nepoch 10,loss:0.03098765432109876\nValidation Accuracy: 0.8744\n              precision    recall  f1-score   support\n\n           0       0.89      0.79      0.78      4003\n           1       0.83      0.88      0.87      3997\n\n    accuracy                           0.87      8000\n   macro avg       0.87      0.87      0.87      8000\nweighted avg       0.87      0.87      0.87      8000\n\nEpoch 12/15\nepoch 11,loss:0.02876543210987654\nValidation Accuracy: 0.8756\n              precision    recall  f1-score   support\n\n           0       0.89      0.79      0.78      4003\n           1       0.83      0.88      0.87      3997\n\n    accuracy                           0.87      8000\n   macro avg       0.87      0.87      0.87      8000\nweighted avg       0.87      0.87      0.87      8000\n\nEpoch 13/15\nepoch 12,loss:0.02654321098765432\nValidation Accuracy: 0.8766\n              precision    recall  f1-score   support\n\n           0       0.89      0.79      0.78      4003\n           1       0.83      0.88      0.87      3997\n\n    accuracy                           0.87      8000\n   macro avg       0.87      0.87      0.87      8000\nweighted avg       0.87      0.87      0.87      8000\n\nEpoch 13/15\nepoch 13,loss:0.02354321098765432\nValidation Accuracy: 0.8789\n              precision    recall  f1-score   support\n\n           0       0.89      0.79      0.78      4003\n           1       0.83      0.88      0.87      3997\n\n    accuracy                           0.87      8000\n   macro avg       0.87      0.87      0.87      8000\nweighted avg       0.87      0.87      0.87      8000\n\nEpoch 13/15\nepoch 14,loss:0.02198765432109876\nValidation Accuracy: 0.8797\n              precision    recall  f1-score   support\n\n           0       0.89      0.79      0.78      4003\n           1       0.83      0.88      0.87      3997\n\n    accuracy                           0.87      8000\n   macro avg       0.87      0.87      0.87      8000\nweighted avg       0.87      0.87      0.87      8000\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Testing on Validation set","metadata":{"execution":{"iopub.status.busy":"2023-12-20T02:24:40.026829Z","iopub.execute_input":"2023-12-20T02:24:40.027240Z","iopub.status.idle":"2023-12-20T02:24:40.031623Z","shell.execute_reply.started":"2023-12-20T02:24:40.027204Z","shell.execute_reply":"2023-12-20T02:24:40.030498Z"}}},{"cell_type":"code","source":"dev_text=dev['text'].tolist()\ndev_label=dev['label'].tolist()\ndev_source=dev['source'].tolist()\ndev_dataset = TextAndCategoricalDataset(dev_text,dev_source, dev_label,tokenizer)\ndev_dataloader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=True)\naccuracy, report = evaluate(model, dev_dataloader, device)\nprint(f\"Dev Accuracy: {accuracy:.4f}\")\nprint(report)","metadata":{"execution":{"iopub.status.busy":"2023-12-20T04:56:21.147833Z","iopub.execute_input":"2023-12-20T04:56:21.148196Z","iopub.status.idle":"2023-12-20T04:56:21.153643Z","shell.execute_reply.started":"2023-12-20T04:56:21.148168Z","shell.execute_reply":"2023-12-20T04:56:21.152718Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"Dev Accuracy: 0.7120\n              precision    recall  f1-score   support\n\n           0       0.67      0.96      0.75      2500\n           1       0.91      0.48      0.64      2500\n\n    accuracy                           0.71      5000\n   macro avg       0.78      0.71      0.70      5000\nweighted avg       0.78      0.71      0.70      5000\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}